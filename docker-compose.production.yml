version: '3.8'

services:
  # Main Prompt Library App
  prompt-library:
    build: 
      context: .
      dockerfile: Dockerfile.production
    logging: *default-logging
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${MAIN_DB_URL}
      - NEXTAUTH_URL=https://sambatv.com
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET}
      - NEXT_PUBLIC_SUPABASE_URL=${NEXT_PUBLIC_SUPABASE_URL}
      - NEXT_PUBLIC_SUPABASE_ANON_KEY=${NEXT_PUBLIC_SUPABASE_ANON_KEY}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - REDIS_URL=redis://redis:6379
    volumes:
      - app-data:/app/data
      - ./logs:/app/logs
    depends_on:
      - redis
    networks:
      - sambatv-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    
  # AI Platform (Agent A's customized Langfuse fork)
  ai-platform:
    build: 
      context: ./sambatv-ai-platform
      dockerfile: Dockerfile
    logging: *default-logging
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${LANGFUSE_DB_URL}
      - NEXTAUTH_URL=https://ai.sambatv.com
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET}
      - REDIS_URL=redis://redis:6379
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_GEMINI_API_KEY=${GOOGLE_GEMINI_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - S3_ENDPOINT=http://minio:9000
      - S3_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - S3_SECRET_KEY=${MINIO_SECRET_KEY}
      - S3_BUCKET_NAME=langfuse-storage
    volumes:
      - langfuse-data:/app/data
      - ./logs/langfuse:/app/logs
    depends_on:
      - langfuse-postgres
      - redis
      - minio
    networks:
      - sambatv-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 90s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    
  # Load Balancer & SSL Termination
  nginx:
    image: nginx:alpine
    logging: *default-logging
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro
      - nginx-cache:/var/cache/nginx
      - nginx-logs:/var/log/nginx
    depends_on:
      - prompt-library
      - ai-platform
    networks:
      - sambatv-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
          cpus: '0.1'
    
  # Dedicated Langfuse PostgreSQL Database (from Task 6)
  langfuse-postgres:
    image: postgres:15-alpine
    logging: *default-logging
    container_name: langfuse-database
    environment:
      POSTGRES_DB: langfuse
      POSTGRES_USER: langfuse_admin
      POSTGRES_PASSWORD: ${LANGFUSE_DB_PASSWORD}
      POSTGRES_MAX_CONNECTIONS: 200
      POSTGRES_SHARED_BUFFERS: 256MB
    volumes:
      - langfuse_data:/var/lib/postgresql/data
      - ./orchestration/langfuse-integration/infrastructure/langfuse-init.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
      - ./orchestration/langfuse-integration/infrastructure/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    ports:
      - "5433:5432"
    networks:
      - sambatv-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U langfuse_admin -d langfuse"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
      
  # Redis Cache
  redis:
    image: redis:7-alpine
    logging: *default-logging
    volumes:
      - redis-data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro
    ports:
      - "6379:6379"
    networks:
      - sambatv-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'
        reservations:
          memory: 256M
          cpus: '0.1'
    command: redis-server /usr/local/etc/redis/redis.conf

  # MinIO S3-Compatible Storage
  minio:
    image: minio/minio:latest
    logging: *default-logging
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY}
    networks:
      - sambatv-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'
        reservations:
          memory: 256M
          cpus: '0.1'
    command: server /data --console-address ":9001"

  # Database Administration (Langfuse)
  langfuse-pgadmin:
    image: dpage/pgadmin4:latest
    container_name: langfuse-db-pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@sambatv.com
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    ports:
      - "8081:80"
    depends_on:
      - langfuse-postgres
    networks:
      - sambatv-network
    restart: unless-stopped
    profiles:
      - admin
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/rules:/etc/prometheus/rules:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - sambatv-network
    restart: unless-stopped
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-sambatv2025}
      GF_INSTALL_PLUGINS: grafana-piechart-panel,grafana-clock-panel
      GF_SERVER_ROOT_URL: https://grafana.ai.sambatv.com
      GF_SECURITY_ALLOW_EMBEDDING: true
    networks:
      - sambatv-network
    restart: unless-stopped
    profiles:
      - monitoring
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

  # Alertmanager for notification routing
  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager/config.yml:/etc/alertmanager/config.yml:ro
      - alertmanager-data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    networks:
      - sambatv-network
    restart: unless-stopped
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.1'

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/host'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/host:ro
    networks:
      - sambatv-network
    restart: unless-stopped
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.1'

  # PostgreSQL Exporter for database metrics
  postgres-exporter:
    image: wrouesnel/postgres_exporter:latest
    ports:
      - "9187:9187"
    environment:
      DATA_SOURCE_NAME: "postgresql://postgres:${LANGFUSE_DB_PASSWORD}@langfuse-postgres:5432/langfuse?sslmode=disable"
    networks:
      - sambatv-network
    restart: unless-stopped
    profiles:
      - monitoring
    depends_on:
      - langfuse-postgres
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.1'

  # Redis Exporter for cache metrics
  redis-exporter:
    image: oliver006/redis_exporter:latest
    ports:
      - "9121:9121"
    environment:
      REDIS_ADDR: "redis://redis:6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-sambatv_redis_2025}
    networks:
      - sambatv-network
    restart: unless-stopped
    profiles:
      - monitoring
    depends_on:
      - redis
    deploy:
      resources:
        limits:
          memory: 64M
          cpus: '0.05'

volumes:
  app-data:
    driver: local
  langfuse-data:
    driver: local
  langfuse_data:
    driver: local
  redis-data:
    driver: local
  nginx-cache:
    driver: local
  nginx-logs:
    driver: local
  minio-data:
    driver: local
  pgadmin-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  alertmanager-data:
    driver: local

networks:
  sambatv-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1

# Production deployment configurations
x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "100m"
    max-file: "3"